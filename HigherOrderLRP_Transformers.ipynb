{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7baae42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "/home/farnoush/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/farnoush/.local/lib/python3.8/site-packages/pandas/core/arrays/masked.py:64: UserWarning: Pandas requires version '1.3.2' or newer of 'bottleneck' (version '1.2.1' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import copy\n",
    "from torch.nn.modules import Module\n",
    "from torch import Tensor\n",
    "from torch import nn as nn\n",
    "import math\n",
    "from transformers import BertForSequenceClassification, BertTokenizer, AutoTokenizer, AutoModelForPreTraining\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import FancyArrowPatch\n",
    "from matplotlib.patches import Arc, RegularPolygon\n",
    "import numpy as np\n",
    "from numpy import radians as rad\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy import stats as st\n",
    "from datasets import load_dataset\n",
    "from detoxify import Detoxify\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc348fd3",
   "metadata": {},
   "source": [
    "## Visualization Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baa8b7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_score_by_abs (score, max_score, min_score):\n",
    "    \"\"\"\n",
    "    Normalize the relevance value (=score), accordingly to the extremal relevance values (max_score and min_score), \n",
    "    for visualization with a diverging colormap.\n",
    "    i.e. rescale positive relevance to the range [0.5, 1.0], and negative relevance to the range [0.0, 0.5],\n",
    "    using the highest absolute relevance for linear interpolation.\n",
    "    \"\"\"\n",
    "    \n",
    "    # CASE 1: positive AND negative scores occur --------------------\n",
    "    if max_score>0 and min_score<0:\n",
    "    \n",
    "        if max_score >= abs(min_score):   # deepest color is positive\n",
    "            if score>=0:\n",
    "                return 0.5 + 0.5*(score/max_score)\n",
    "            else:\n",
    "                return 0.5 - 0.5*(abs(score)/max_score)\n",
    "\n",
    "        else:                             # deepest color is negative\n",
    "            if score>=0:\n",
    "                return 0.5 + 0.5*(score/abs(min_score))\n",
    "            else:\n",
    "                return 0.5 - 0.5*(score/min_score)   \n",
    "    \n",
    "    # CASE 2: ONLY positive scores occur -----------------------------       \n",
    "    elif max_score>0 and min_score>=0: \n",
    "        if max_score == min_score:\n",
    "            return 1.0\n",
    "        else:\n",
    "            return 0.5 + 0.5*(score/max_score)\n",
    "    \n",
    "    # CASE 3: ONLY negative scores occur -----------------------------\n",
    "    elif max_score<=0 and min_score<0: \n",
    "        if max_score == min_score:\n",
    "            return 0.0\n",
    "        else:\n",
    "            return 0.5 - 0.5*(score/min_score)    \n",
    "  \n",
    "      \n",
    "def getRGB (c_tuple):\n",
    "    return \"#%02x%02x%02x\"%(int(c_tuple[0]*255), int(c_tuple[1]*255), int(c_tuple[2]*255))\n",
    "\n",
    "     \n",
    "def span_word (word, score, colormap):\n",
    "    return \"<span style=\\\"background-color:\"+getRGB(colormap(score))+\"\\\">\"+word+\"</span>\"\n",
    "\n",
    "\n",
    "def html_heatmap (words, scores, cmap_name=\"bwr\"):\n",
    "    \"\"\"\n",
    "    Return word-level heatmap in HTML format,\n",
    "    with words being the list of words (as string),\n",
    "    scores the corresponding list of word-level relevance values,\n",
    "    and cmap_name the name of the matplotlib diverging colormap.\n",
    "    \"\"\"\n",
    "    \n",
    "    colormap  = plt.get_cmap(cmap_name)\n",
    "     \n",
    "    assert len(words)==len(scores)\n",
    "    max_s     = max(scores)\n",
    "    min_s     = min(scores)\n",
    "    \n",
    "    output_text = \"\"\n",
    "    \n",
    "    for idx, w in enumerate(words):\n",
    "        score       = rescale_score_by_abs(scores[idx], max_s, min_s)\n",
    "        output_text = output_text + span_word(w, score, colormap) + \" \"\n",
    "    \n",
    "    return output_text + \"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9108a894",
   "metadata": {},
   "source": [
    "## LRP Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcc75667",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stabilize(z):\n",
    "    return z + ((z == 0.).to(z) + z.sign()) * 1e-6\n",
    "\n",
    "\n",
    "def modified_layer(\n",
    "        layer,\n",
    "        transform\n",
    "):\n",
    "    \"\"\"\n",
    "    This function creates a copy of a layer and modify\n",
    "    its parameters based on a transformation function 'transform'.\n",
    "    -------------------\n",
    "    :param layer: A layer which its parameters are going to be transformed.\n",
    "    :param transform: A transformation function.\n",
    "    :return: A new layer with modified parameters.\n",
    "    \"\"\"\n",
    "    new_layer = copy.deepcopy(layer)\n",
    "\n",
    "    try:\n",
    "        new_layer.weight = torch.nn.Parameter(transform(layer.weight.float()))\n",
    "    except AttributeError as e:\n",
    "        print(e)\n",
    "\n",
    "    try:\n",
    "        new_layer.bias = torch.nn.Parameter(transform(layer.bias.float()))\n",
    "    except AttributeError as e:\n",
    "        print(e)\n",
    "\n",
    "    return new_layer\n",
    "\n",
    "\n",
    "class ModifiedLinear(Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            fc,\n",
    "            transform\n",
    "    ):\n",
    "        super(ModifiedLinear, self).__init__()\n",
    "        self.fc = fc\n",
    "        \n",
    "        # TODO: Do not set bias to 0.\n",
    "        # self.fc.bias = torch.nn.Parameter(torch.zeros(self.fc.bias.shape))\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.modified_fc = modified_layer(layer=fc, transform=transform)\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            x: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        z = self.fc(x)\n",
    "        zp = self.modified_fc(x)\n",
    "        zp = stabilize(zp)\n",
    "        return (zp.double() * (z.double() / zp.double()).data.double()).float()\n",
    "\n",
    "    \n",
    "class ModifiedLayerNorm(Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            norm_layer,\n",
    "            normalized_shape,\n",
    "            eps=1e-12\n",
    "    ):\n",
    "        super(ModifiedLayerNorm, self).__init__()\n",
    "        # TODO: Do not set bias to 0.\n",
    "        # norm_layer.bias = torch.nn.Parameter(torch.zeros(norm_layer.bias.shape))\n",
    "        \n",
    "        self.norm_layer = norm_layer\n",
    "        self.weight = norm_layer.weight\n",
    "        self.bias = norm_layer.bias\n",
    "        self.normalized_shape = normalized_shape\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            input: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "\n",
    "        z = self.norm_layer(input)\n",
    "        mean = input.mean(dim=-1, keepdim=True)\n",
    "        var = torch.var(input, unbiased=False, dim=-1, keepdim=True)\n",
    "        denominator = torch.sqrt(var + self.eps)\n",
    "        denominator = denominator.detach()\n",
    "        zp = ((input - mean) / denominator) * self.weight + self.bias\n",
    "        zp = stabilize(zp)\n",
    "        return (zp.double() * (z.double() / zp.double()).data.double()).float()\n",
    "    \n",
    "class ModifiedAct(Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        act\n",
    "    ):\n",
    "        super(ModifiedAct, self).__init__()\n",
    "        self.modified_act = nn.Identity()\n",
    "        self.act = act\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        x\n",
    "    ):\n",
    "        z = self.act(x)\n",
    "        zp = self.modified_act(x)\n",
    "        zp = stabilize(zp)\n",
    "        return (zp.double() * (z.double() / zp.double()).data.double()).float()\n",
    "    \n",
    "class ModifiedTanh(Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        act\n",
    "    ):\n",
    "        super(ModifiedTanh, self).__init__() \n",
    "        self.act = act\n",
    "        self.modified_act = nn.Identity()\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        x\n",
    "    ):\n",
    "        z = self.act(x)\n",
    "        zp = self.modified_act(x)\n",
    "        zp = stabilize(zp)\n",
    "        return (zp.double() * (z.double() / zp.double()).data.double()).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e13d92",
   "metadata": {},
   "source": [
    "## LRP Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edd4a749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gamma(\n",
    "        gam: float = 0.0\n",
    ") -> Tensor:\n",
    "\n",
    "    def modify_parameters(parameters: Tensor):\n",
    "        return parameters + (gam * parameters.clamp(min=0))\n",
    "\n",
    "    return modify_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f3fffb",
   "metadata": {},
   "source": [
    "## BERT Model's Building Blocks\n",
    "\n",
    "<img src=\"BERT.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834bd0b9",
   "metadata": {},
   "source": [
    "## LRP for BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "259fa413",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedBertSelfAttention(nn.Module):\n",
    "    def __init__(self, self_attention):\n",
    "        super(ModifiedBertSelfAttention, self).__init__()\n",
    "        self.query = ModifiedLinear(fc=self_attention.query, transform=gamma())\n",
    "        self.key = ModifiedLinear(fc=self_attention.key, transform=gamma())\n",
    "        self.value = ModifiedLinear(fc=self_attention.value, transform=gamma())\n",
    "        \n",
    "        self.dropout = self_attention.dropout   \n",
    "        self.num_attention_heads = self_attention.num_attention_heads\n",
    "        self.attention_head_size = self_attention.attention_head_size\n",
    "        self.all_head_size = self_attention.all_head_size\n",
    "        \n",
    "    def transpose_for_scores(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n",
    "        x = x.view(new_x_shape)\n",
    "        return x.permute(0, 2, 1, 3)\n",
    "    \n",
    "    def forward(self, hidden_states):\n",
    "        key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
    "        query_layer = self.transpose_for_scores(self.query(hidden_states))\n",
    "        value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
    "        \n",
    "        # Attention scores\n",
    "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
    "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
    "        \n",
    "        attention_probs = nn.Softmax(dim=-1)(attention_scores).detach()\n",
    "        \n",
    "        \n",
    "        context_layer = torch.matmul(attention_probs, value_layer)\n",
    "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
    "        \n",
    "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
    "        context_layer = context_layer.view(new_context_layer_shape)\n",
    "        outputs = context_layer\n",
    "        \n",
    "        return outputs\n",
    "        \n",
    "class ModifiedBertSelfOutput(nn.Module): \n",
    "    def __init__(self, self_output):\n",
    "        super(ModifiedBertSelfOutput, self).__init__()\n",
    "        self.dense = ModifiedLinear(fc=self_output.dense, transform=gamma())\n",
    "        self.LayerNorm = ModifiedLayerNorm(norm_layer=self_output.LayerNorm,\n",
    "                                           normalized_shape=self_output.dense.weight.shape[1])\n",
    "        self.dropout = self_output.dropout\n",
    "        \n",
    "    def forward(self, hidden_states, input_tensor):\n",
    "        hidden_states = self.dense(hidden_states)                \n",
    "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
    "\n",
    "        return hidden_states\n",
    "        \n",
    "    \n",
    "class ModifiedBertAttention(nn.Module):\n",
    "    def __init__(self, attention):\n",
    "        super(ModifiedBertAttention, self).__init__()\n",
    "        self.self = ModifiedBertSelfAttention(attention.self)\n",
    "        self.output = ModifiedBertSelfOutput(attention.output)\n",
    "        \n",
    "    def forward(self, hidden_states):\n",
    "        self_output = self.self(hidden_states)\n",
    "        attention_output = self.output(self_output, hidden_states)\n",
    "        \n",
    "        return attention_output\n",
    "        \n",
    "        \n",
    "class ModifiedBertIntermediate(nn.Module):\n",
    "    def __init__(self, intermediate):\n",
    "        super(ModifiedBertIntermediate, self).__init__()\n",
    "        self.dense = ModifiedLinear(fc=intermediate.dense, transform=gamma())\n",
    "        self.intermediate_act_fn = ModifiedAct(intermediate.intermediate_act_fn)\n",
    "        \n",
    "    def forward(self, hidden_states):\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "        hidden_states = self.intermediate_act_fn(hidden_states)\n",
    "        return hidden_states  \n",
    "\n",
    "# -------- Second-Order --------\n",
    "class ModifiedBertIntermediateSecondOrder(nn.Module):\n",
    "    def __init__(self, intermediate):\n",
    "        super(ModifiedBertIntermediateSecondOrder, self).__init__()\n",
    "        self.dense = ModifiedLinear(fc=intermediate.dense, transform=gamma())\n",
    "        self.intermediate_act_fn = intermediate.intermediate_act_fn\n",
    "        \n",
    "    def forward(self, hidden_states, mask):\n",
    "        P_t = self.dense(hidden_states)\n",
    "        Q_t = P_t * (self.intermediate_act_fn(P_t) / P_t).data\n",
    "        H_t = Q_t * mask + Q_t.data * (1 - mask)\n",
    "        return H_t\n",
    "# -----------------------------\n",
    "\n",
    "class ModifiedBertOutput(nn.Module):\n",
    "    def __init__(self, output):\n",
    "        super(ModifiedBertOutput, self).__init__()\n",
    "        self.dense = ModifiedLinear(fc=output.dense, transform=gamma())\n",
    "        self.LayerNorm = ModifiedLayerNorm(norm_layer=output.LayerNorm,\n",
    "                                           normalized_shape=output.dense.weight.shape[1])\n",
    "        self.dropout = output.dropout\n",
    "        \n",
    "    def forward(self, hidden_states, input_tensor):\n",
    "        hidden_states = self.dense(hidden_states)                \n",
    "        hidden_states = self.LayerNorm(hidden_states + input_tensor) \n",
    "\n",
    "        return hidden_states\n",
    "    \n",
    "class ModifiedBertLayer(nn.Module):\n",
    "    def __init__(self, layer):\n",
    "        super(ModifiedBertLayer, self).__init__()\n",
    "        self.attention = ModifiedBertAttention(layer.attention)\n",
    "        self.intermediate = ModifiedBertIntermediate(layer.intermediate)\n",
    "        self.output = ModifiedBertOutput(layer.output)\n",
    "        \n",
    "    def forward(self, hidden_states):\n",
    "        attention_output = self.attention(hidden_states)\n",
    "        intermediate_output = self.intermediate(attention_output)\n",
    "        hidden_states = self.output(intermediate_output, attention_output)\n",
    "        \n",
    "        return hidden_states\n",
    "\n",
    "# -------- Second-Order --------\n",
    "class ModifiedBertLayerSecondOrder(nn.Module):\n",
    "    def __init__(self, layer):\n",
    "        super(ModifiedBertLayerSecondOrder, self).__init__()\n",
    "        self.attention = ModifiedBertAttention(layer.attention)\n",
    "        self.intermediate = ModifiedBertIntermediateSecondOrder(layer.intermediate)\n",
    "        self.output = ModifiedBertOutput(layer.output)\n",
    "        \n",
    "    def forward(self, hidden_states, mask):\n",
    "        attention_output = self.attention(hidden_states)\n",
    "        intermediate_output = self.intermediate(attention_output, mask)\n",
    "        attention_output  = attention_output * mask + attention_output.data * (1 - mask)\n",
    "        z = self.output(intermediate_output, attention_output)\n",
    "        return z\n",
    "# -----------------------------\n",
    "        \n",
    "class ModifiedBertEncoder(nn.Module):\n",
    "    def __init__(self, encoder, order):\n",
    "        super(ModifiedBertEncoder, self).__init__()\n",
    "        self.order = order\n",
    "        layers = []\n",
    "        n = len(encoder.layer)\n",
    "        for i, layer in enumerate(encoder.layer):\n",
    "            if order == 2:\n",
    "                # Change the last 2 BERT layers.\n",
    "                if (i == n-2 or i == n-3):\n",
    "                    layers.append(ModifiedBertLayerSecondOrder(layer))\n",
    "                else:\n",
    "                    layers.append(ModifiedBertLayer(layer)) \n",
    "            else:\n",
    "                layers.append(ModifiedBertLayer(layer))\n",
    "        self.layer = nn.ModuleList(layers)\n",
    "        \n",
    "    def forward(self, hidden_states):        \n",
    "        for i, layer in enumerate(self.layer):\n",
    "            hidden_states = layer(hidden_states)      \n",
    "        return hidden_states\n",
    "    \n",
    "class ModifiedBertPooler(nn.Module):\n",
    "    def __init__(self, pooler):\n",
    "        super(ModifiedBertPooler, self).__init__()\n",
    "        self.dense = ModifiedLinear(fc=pooler.dense, transform=gamma())\n",
    "        self.activation = ModifiedTanh(pooler.activation)\n",
    "        \n",
    "    def forward(self, hidden_states):\n",
    "        first_token_tensor = hidden_states[:, 0]\n",
    "        pooled_output = self.dense(first_token_tensor)\n",
    "        pooled_output = self.activation(pooled_output)\n",
    "        \n",
    "        return pooled_output\n",
    "\n",
    "class ModifiedBertModel(nn.Module):\n",
    "    def __init__(self, bert, embeddings, order):\n",
    "        super(ModifiedBertModel, self).__init__()\n",
    "        self.embeddings = embeddings\n",
    "        self.encoder = ModifiedBertEncoder(bert.encoder, order)\n",
    "        self.pooler = ModifiedBertPooler(bert.pooler)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        hidden_states = self.embeddings(x)    \n",
    "        hidden_states = self.encoder(hidden_states)\n",
    "        hidden_states = self.pooler(hidden_states)\n",
    "        \n",
    "        return hidden_states\n",
    "    \n",
    "class ModifiedBertForSequenceClassification(nn.Module):\n",
    "    def __init__(self, bert_classification, embeddings, order=1):\n",
    "        super(ModifiedBertForSequenceClassification, self).__init__()\n",
    "        self.bert = ModifiedBertModel(bert_classification.bert, embeddings, order)\n",
    "        self.dropout = bert_classification.dropout\n",
    "        self.classifier = ModifiedLinear(fc=bert_classification.classifier, transform=gamma())\n",
    "        self.order = order\n",
    "        \n",
    "    def forward(self, x):\n",
    "        hidden_states = self.bert(x)\n",
    "        hidden_states = self.classifier(hidden_states)\n",
    "        \n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3fd8de",
   "metadata": {},
   "source": [
    "## LRP for BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b9a74c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrp(model, x, target, indices, pretrained_embeddings):\n",
    "    A = {}\n",
    "    \n",
    "    hidden_states = pretrained_embeddings(input_ids=x['input_ids'], token_type_ids=x['token_type_ids'])\n",
    "    A['hidden_states'] = hidden_states\n",
    "    attn_input = hidden_states\n",
    "    \n",
    "    if model.order == 2:\n",
    "        M = torch.eye(hidden_states.shape[1])\n",
    "        j, k = indices\n",
    "        Mj = M[j].unsqueeze(0).unsqueeze(2)\n",
    "        Mk = M[k].unsqueeze(0).unsqueeze(2)\n",
    "    \n",
    "    n = len(model.bert.encoder.layer)\n",
    "    for i, layer in enumerate(model.bert.encoder.layer):\n",
    "            attn_inputdata = attn_input.data\n",
    "            attn_inputdata.requires_grad_(True) \n",
    "                        \n",
    "            A['attn_input_{}_data'.format(i)] = attn_inputdata\n",
    "            A['attn_input_{}'.format(i)] = attn_input\n",
    "            \n",
    "            if model.order == 2:\n",
    "                if i == n-2:\n",
    "                    output = model.bert.encoder.layer[i](A['attn_input_{}_data'.format(i)], Mj)\n",
    "                elif i == n-3:\n",
    "                    output = model.bert.encoder.layer[i](A['attn_input_{}_data'.format(i)], Mk)\n",
    "                else:\n",
    "                    output = model.bert.encoder.layer[i](A['attn_input_{}_data'.format(i)])  \n",
    "            else:\n",
    "                output = model.bert.encoder.layer[i](A['attn_input_{}_data'.format(i)])\n",
    "            attn_input = output\n",
    "            \n",
    "    outputdata = output.data\n",
    "    outputdata.requires_grad_(True)\n",
    "    \n",
    "    pooled = model.bert.pooler(outputdata)\n",
    "    pooleddata = pooled.data\n",
    "    pooleddata.requires_grad_(True) \n",
    "        \n",
    "    logits = model.classifier(pooleddata)\n",
    "    Rout = (logits * target).sum()\n",
    "    \n",
    "    Rout.backward()\n",
    "    ((pooleddata.grad)*pooled).sum().backward()\n",
    "                \n",
    "    Rpool = ((outputdata.grad)*output)\n",
    "    R_ = Rpool\n",
    "    \n",
    "    R_all = []\n",
    "    for i, layer in list(enumerate(model.bert.encoder.layer))[::-1]:\n",
    "        R_.sum().backward()\n",
    "        R_grad = A['attn_input_{}_data'.format(i)].grad\n",
    "        R_attn =  (R_grad)*A['attn_input_{}'.format(i)]\n",
    "        \n",
    "        R_ = R_attn\n",
    "        R_all.append(R_.sum(2).detach().cpu().numpy().squeeze().sum())\n",
    "\n",
    "    R = R_.sum(2).detach().cpu().numpy()\n",
    "    \n",
    "    return R, None, Rout, R_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f994a12",
   "metadata": {},
   "source": [
    "## Pixel Flipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "249cecd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flipping(x, attributions, tokenizer, model, label):\n",
    "    # UNK_IDX = tokenizer.unk_token_id  # an out-of-vocab token\n",
    "    inds_sorted = np.argsort(np.abs(attributions))\n",
    "    sorted_attributions = attributions[inds_sorted]\n",
    "    \n",
    "    fracs = np.linspace(0, 1, 11)\n",
    "    input_ids = x['input_ids']\n",
    "    token_type_ids=x['token_type_ids']\n",
    "    \n",
    "    if False:\n",
    "        inds_ = np.array(list(range(input_ids.shape[-1])))\n",
    "        remain_inds = np.array(inds_)\n",
    "        np.random.shuffle(remain_inds)\n",
    "\n",
    "        inds_sorted = remain_inds\n",
    "\n",
    "    \n",
    "    inputs0 = input_ids.clone()\n",
    "    \n",
    "    y0 = model(input_ids=input_ids, token_type_ids=token_type_ids)['logits'].detach().numpy().squeeze()\n",
    "    \n",
    "    N = len(input_ids[0])\n",
    "    errors = []\n",
    "    for frac in fracs:\n",
    "        inds_generator = iter(inds_sorted)\n",
    "        n_flip=int(np.ceil(frac*N))\n",
    "        inds_flip = [next(inds_generator) for i in range(n_flip)]\n",
    "\n",
    "        inputs = inputs0\n",
    "        for i in inds_flip:\n",
    "            inputs[:,i] = UNK_IDX\n",
    "            \n",
    "        y = model(input_ids=inputs, token_type_ids=token_type_ids)['logits'].detach().numpy().squeeze()\n",
    "        err = np.sum((y0-y)**2)\n",
    "        \n",
    "        errors.append(err)\n",
    "        \n",
    "    return errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a83213",
   "metadata": {},
   "source": [
    "## Explain BERT trained on the SST2 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e07bdaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset sst2 (/home/farnoush/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4954ef5b9b24ada824612786c4845a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "(0, 0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#fff6f6\">[CLS]</span> <span style=\"background-color:#fffefe\">un</span> <span style=\"background-color:#e3e3ff\">##fl</span> <span style=\"background-color:#b0b0ff\">##in</span> <span style=\"background-color:#a0a0ff\">##ching</span> <span style=\"background-color:#ffcece\">##ly</span> <span style=\"background-color:#ff0000\">bleak</span> <span style=\"background-color:#ffe2e2\">and</span> <span style=\"background-color:#ff8282\">desperate</span> <span style=\"background-color:#fff2f2\">[SEP]</span> \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#ececff\">[CLS]</span> <span style=\"background-color:#eeeeff\">un</span> <span style=\"background-color:#9a9aff\">##fl</span> <span style=\"background-color:#7979ff\">##in</span> <span style=\"background-color:#2e2eff\">##ching</span> <span style=\"background-color:#ffaaaa\">##ly</span> <span style=\"background-color:#ff0000\">bleak</span> <span style=\"background-color:#fff0f0\">and</span> <span style=\"background-color:#ffd6d6\">desperate</span> <span style=\"background-color:#aeaeff\">[SEP]</span> \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#c2c2ff\">[CLS]</span> <span style=\"background-color:#c2c2ff\">un</span> <span style=\"background-color:#babaff\">##fl</span> <span style=\"background-color:#a3a3ff\">##in</span> <span style=\"background-color:#9e9eff\">##ching</span> <span style=\"background-color:#ffc0c0\">##ly</span> <span style=\"background-color:#ff0000\">bleak</span> <span style=\"background-color:#fffafa\">and</span> <span style=\"background-color:#ffcccc\">desperate</span> <span style=\"background-color:#bebeff\">[SEP]</span> \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#b6b6ff\">[CLS]</span> <span style=\"background-color:#f2f2ff\">un</span> <span style=\"background-color:#a0a0ff\">##fl</span> <span style=\"background-color:#f2f2ff\">##in</span> <span style=\"background-color:#0000ff\">##ching</span> <span style=\"background-color:#ffeaea\">##ly</span> <span style=\"background-color:#ff6464\">bleak</span> <span style=\"background-color:#fcfcff\">and</span> <span style=\"background-color:#ffd2d2\">desperate</span> <span style=\"background-color:#c6c6ff\">[SEP]</span> \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#ceceff\">[CLS]</span> <span style=\"background-color:#babaff\">un</span> <span style=\"background-color:#d8d8ff\">##fl</span> <span style=\"background-color:#6868ff\">##in</span> <span style=\"background-color:#0000ff\">##ching</span> <span style=\"background-color:#ffd2d2\">##ly</span> <span style=\"background-color:#ff0e0e\">bleak</span> <span style=\"background-color:#fffefe\">and</span> <span style=\"background-color:#ffcccc\">desperate</span> <span style=\"background-color:#8a8aff\">[SEP]</span> \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#fff8f8\">[CLS]</span> <span style=\"background-color:#e3e3ff\">un</span> <span style=\"background-color:#dcdcff\">##fl</span> <span style=\"background-color:#a0a0ff\">##in</span> <span style=\"background-color:#6969ff\">##ching</span> <span style=\"background-color:#ffd8d8\">##ly</span> <span style=\"background-color:#ff0000\">bleak</span> <span style=\"background-color:#fff6f6\">and</span> <span style=\"background-color:#ffd6d6\">desperate</span> <span style=\"background-color:#f2f2ff\">[SEP]</span> \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#ffcaca\">[CLS]</span> <span style=\"background-color:#f8f8ff\">un</span> <span style=\"background-color:#fefeff\">##fl</span> <span style=\"background-color:#d6d6ff\">##in</span> <span style=\"background-color:#e6e6ff\">##ching</span> <span style=\"background-color:#ffd0d0\">##ly</span> <span style=\"background-color:#ff0000\">bleak</span> <span style=\"background-color:#ffecec\">and</span> <span style=\"background-color:#ffd3d3\">desperate</span> <span style=\"background-color:#ffa0a0\">[SEP]</span> \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#ffdede\">[CLS]</span> <span style=\"background-color:#fcfcff\">un</span> <span style=\"background-color:#eeeeff\">##fl</span> <span style=\"background-color:#b3b3ff\">##in</span> <span style=\"background-color:#a3a3ff\">##ching</span> <span style=\"background-color:#ffbcbc\">##ly</span> <span style=\"background-color:#ff0000\">bleak</span> <span style=\"background-color:#ffdada\">and</span> <span style=\"background-color:#ffcccc\">desperate</span> <span style=\"background-color:#ffc8c8\">[SEP]</span> \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#ffa8a8\">[CLS]</span> <span style=\"background-color:#fcfcff\">un</span> <span style=\"background-color:#ececff\">##fl</span> <span style=\"background-color:#aeaeff\">##in</span> <span style=\"background-color:#c8c8ff\">##ching</span> <span style=\"background-color:#ffc8c8\">##ly</span> <span style=\"background-color:#ff1111\">bleak</span> <span style=\"background-color:#ffb0b0\">and</span> <span style=\"background-color:#ff0000\">desperate</span> <span style=\"background-color:#ff6c6c\">[SEP]</span> \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#d6d6ff\">[CLS]</span> <span style=\"background-color:#fffcfc\">un</span> <span style=\"background-color:#fefeff\">##fl</span> <span style=\"background-color:#ececff\">##in</span> <span style=\"background-color:#eaeaff\">##ching</span> <span style=\"background-color:#fff0f0\">##ly</span> <span style=\"background-color:#ffb3b3\">bleak</span> <span style=\"background-color:#ffeeee\">and</span> <span style=\"background-color:#ffe0e0\">desperate</span> <span style=\"background-color:#0000ff\">[SEP]</span> \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean_error = np.zeros(11)\n",
    "num_data = 0\n",
    "relevance = []\n",
    "relevance_all = []\n",
    "logits = []\n",
    "acc = 0\n",
    "\n",
    "# Load dataset.\n",
    "dataset = load_dataset(\"sst2\", \"default\")\n",
    "\n",
    "# Load model.\n",
    "model = BertForSequenceClassification.from_pretrained(\"textattack/bert-base-uncased-SST-2\")\n",
    "pretrained_embeddings = model.bert.embeddings\n",
    "modified_model = ModifiedBertForSequenceClassification(model,\n",
    "                                                       pretrained_embeddings,\n",
    "                                                       order=2)\n",
    "modified_model.eval()\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"textattack/bert-base-uncased-SST-2\")\n",
    "UNK_IDX = tokenizer.unk_token_id  # an out-of-vocab token\n",
    "print(UNK_IDX)\n",
    "\n",
    "i = 1\n",
    "sentence = dataset['validation']['sentence'][i]\n",
    "target = torch.nn.functional.one_hot(\n",
    "    torch.tensor(dataset['validation']['label'][i]), num_classes=2)\n",
    "\n",
    "x = tokenizer(sentence, return_tensors=\"pt\")\n",
    "words = tokenizer.convert_ids_to_tokens(x['input_ids'].squeeze())\n",
    "\n",
    "relevance = []\n",
    "for indices in zip(range(len(words)), range(len(words))):\n",
    "    R, pred, logit, R_all = lrp(modified_model, x, target, indices, pretrained_embeddings)\n",
    "    relevance.append(R.squeeze())\n",
    "    print(indices)\n",
    "    display(HTML(html_heatmap(words, R.squeeze())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5b488d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 6 6 6 6 6 6 8]\n",
      "2.4868257\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#ccccff\">un</span> <span style=\"background-color:#fafaff\">##fl</span> <span style=\"background-color:#e2e2ff\">##in</span> <span style=\"background-color:#7070ff\">##ching</span> <span style=\"background-color:#fff0f0\">##ly</span> <span style=\"background-color:#ff0000\">bleak</span> <span style=\"background-color:#ff5050\">and</span> <span style=\"background-color:#ff4e4e\">desperate</span> \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "relevance = np.array(relevance)\n",
    "max_arg = np.argmax(relevance, axis=1)\n",
    "mean_rel =  np.mean(relevance, axis=1)\n",
    "print(max_arg[1:-1])\n",
    "print(relevance.sum())\n",
    "display(HTML(html_heatmap(words[1:-1], mean_rel[1:-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f180d32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
